{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bb7dfa-044e-4b1e-b0ac-6515b93ab39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98344635-9289-4e87-a93c-42a83d098ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"archive/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcbdd8c-a718-4081-83aa-393fbf294d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe90f4a-74c8-45d2-a9b8-b9ee2a0987e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data.columns[0], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c041b6-604e-4c86-b61b-88aba2f6060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297495e3-4ced-43c1-bae6-42ad0b10cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_data = pd.read_csv(\"archive/Mapping.csv\")\n",
    "emoji_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acc114b-e89a-4a0d-bdf0-a45517084c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cbea15-5b8c-4902-8730-2748f8187260",
   "metadata": {},
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59be486c-622b-4962-8bd4-9d4942ec0e1e",
   "metadata": {},
   "source": [
    "## Text Cleaning Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba9473-d89f-42e3-beae-0f1318dde8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+\",\"\", text)\n",
    "    text = re.sub(r\"@\\w+\",\"\", text)\n",
    "    text = re.sub(r\"#\\w+\",\"\", text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9 ]+', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "data[\"TEXT\"] = data[\"TEXT\"].apply(clean_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69881c5-3ad8-4fde-8c8e-063268a2c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a16e0c-ac2c-48f9-86fd-01cf736bb74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"TEXT\"]\n",
    "Y = data[\"Label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5347823-c4ba-4540-a190-da9450989104",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d7418-4602-48f2-9ff3-28d627a6a137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 42, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e8e446-2d4d-48a2-89e7-c2a7c7e86930",
   "metadata": {},
   "source": [
    "## Tokenizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e96716-f141-40c5-aa95-af5bd9e570b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.text_to_sequences(X_test)\n",
    "word2index = tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9af83db-d539-428c-b97c-7ce3636e7120",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b026d2-4891-4b2a-bd85-12fa9ab5066c",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1542d9d9-5d8d-4cee-8f75-4368f4fc67b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5905bedd-e609-4e88-b6ef-6dc2c53a6af8",
   "metadata": {},
   "source": [
    "## Padding Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb028e4e-fc97-4144-aedf-9defa42f0700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maxlen(data):\n",
    "    maxlen = 0\n",
    "    for index, row in data.iterrows():\n",
    "        sent = row[\"TEXT\"].split()\n",
    "        maxlen = max(maxlen, len(sent))\n",
    "    return maxlen\n",
    "max_len = get_maxlen(data)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df51a6c-6be2-40f5-bc9c-d325761ff0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 40\n",
    "def padding(seq):\n",
    "    data = pad_sequences(seq, maxlen = max_length, padding = \"post\", truncating = 'post')\n",
    "    return data\n",
    "X_train_pad = padding(X_train_seq)\n",
    "X_test_pad = padding(X_test_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8d2556-1c45-4eec-8bb1-696b760aa86f",
   "metadata": {},
   "source": [
    "## Convert Labels to Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd819399-4d0b-4abf-ab51-ee6f15c7696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "Y_train = to_categorical(Y)\n",
    "Y_test = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f92969-7e99-43ab-bc49-c9c1e5a6c0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be18c1c9-d409-4cd1-959e-0af26926bf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0])\n",
    "print(X_train_pad[0], Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146a62ac-60b9-42dd-86b9-98c68bcce4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_output = len(emoji_data)\n",
    "num_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25489179-cce7-40d4-a1a2-a49d464f48fc",
   "metadata": {},
   "source": [
    "## Building and Training LSTM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b7179-5db8-4d39-833f-e477b1cc530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "embed_size = 100\n",
    "embedding_matrix = np.zeros(len(word2index)+1, embed_size)\n",
    "for word, i in word2index.items():\n",
    "    embed_vector = wv[word]\n",
    "    embedding_matrix[i] = embed_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee35be-6e8f-40b4-93fa-36ac45164734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = len(word2index)+1, output_dim = embed_size,  trainable = False, weight = [embedding_matrix]))\n",
    "model.add(Bidirectional(LSTM(units = 512, return_sequences=True)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(units=256)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=20, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312cf13e-9c4b-4c32-9aca-b54125dfed60",
   "metadata": {},
   "source": [
    "## Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b907ad-a2f3-4861-a5c8-f0880c72bc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571e40da-4e02-41e6-9818-9b47ca64bbf6",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba83b0c-cc58-45f7-88ab-67310fa882a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_pad,Y_train, epochs = 10, batch_size = 128, validation_split = 0.2, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b5905-fb45-4bd0-a212-20a48623b593",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb23829-9bb8-4126-a53b-b0d92d2fee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test_pad, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
